{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3gHKIIAY3bsT"},"outputs":[],"source":["!pip install --upgrade google-cloud-vision\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SSiz1erR4X6Y"},"outputs":[],"source":["!pip install utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"extDHafv3e1f"},"outputs":[],"source":["import os\n","import io\n","import numpy as np\n","import platform\n","from PIL import ImageFont, ImageDraw, Image\n","import utils\n","import matplotlib.pyplot as plt\n","import cv2\n","from google.cloud import vision\n","from google.cloud import vision_v1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hofDw1-m3hK1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k3Q3hPRy3ifA"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q4xqDr_63j4E"},"outputs":[],"source":["os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'ultra-airway-412008-b349834297f5.json'\n","\n","client_options = {'api_endpoint': 'eu-vision.googleapis.com'}\n","client = vision.ImageAnnotatorClient(client_options=client_options)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TR3xpymf3z_j"},"outputs":[],"source":["from google.cloud import vision\n","import pandas as pd\n","df = pd.read_csv('data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pQhUfSFEIw06"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BTItWAvDJqXK"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pc8PSx03JtJI"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6pZjCRzyS9mL"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"eoecObr9Vt75"},"source":["## 썸네일 텍스트 컬럼 추가 코드\n","1. 이미지 파일로 추가\n","2. 썸네일 url로 추가\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S3WcyRyHIVZ7"},"outputs":[],"source":["#이미지 파일\n","from google.cloud import vision_v1\n","\n","def ocr_with_google_cloud_vision(image_url):\n","    with open(image_path, 'rb') as image_file:\n","        content = image_file.read()\n","\n","    image = vision.Image(content=content)\n","\n","    response = client.text_detection(image=image)\n","    texts = response.text_annotations\n","\n","    if texts:\n","        return texts[0].description\n","    else:\n","        return ''\n","\n","for idx, col in 이미지 경로 리스트\n","    df.loc[idx, '썸네일 문자'] = ocr_with_google_cloud_vision(col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yW_txiRH3qcD"},"outputs":[],"source":["#url로 추가\n","from google.cloud import vision_v1\n","\n","def ocr_with_google_cloud_vision(image_url):\n","    client = vision_v1.ImageAnnotatorClient()\n","    image = vision_v1.Image()\n","    image.source.image_uri = image_url\n","\n","    response = client.text_detection(image=image)\n","    texts = response.text_annotations\n","\n","    if texts:\n","        # 첫 번째 감지된 텍스트를 반환합니다.\n","        return texts[0].description\n","    else:\n","        return ''\n","\n","# DataFrame을 반복하며 '썸네일 문자' 열을 업데이트합니다.\n","# for idx, col in enumerate(df['썸네일 주소']):\n","    # df.loc[idx, '썸네일 문자'] = ocr_with_google_cloud_vision(col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w5-0HvsI4kIl"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"9EhFNrU9VdUF"},"source":["## 유해성 수치 컬럼 추가 코드\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_vQRnSAdB7z2"},"outputs":[],"source":["def detect_safe_search(image_url):\n","    \"\"\"Detects unsafe features in the file.\"\"\"\n","    from google.cloud import vision\n","\n","    client = vision_v1.ImageAnnotatorClient()\n","    image = vision_v1.Image()\n","    image.source.image_uri = image_url\n","\n","\n","\n","    response = client.safe_search_detection(image=image)\n","    safe = response.safe_search_annotation\n","\n","    # Names of likelihood from google.cloud.vision.enums\n","    likelihood_name = (0,10,20,30,40,50)\n","    # print(\"Safe search:\")\n","\n","    # print(f\"adult: {likelihood_name[safe.adult]}\")\n","    # print(f\"medical: {likelihood_name[safe.medical]}\")\n","    # print(f\"spoofed: {likelihood_name[safe.spoof]}\")\n","    # print(f\"violence: {likelihood_name[safe.violence]}\")\n","    # print(f\"racy: {likelihood_name[safe.racy]}\")\n","    # print(f\"adult: {likelihood_name[safe.adult]}\")\n","    # print(f\"medical: {likelihood_name[safe.medical]}\")\n","    # print(f\"spoofed: {likelihood_name[safe.spoof]}\")\n","    # print(f\"violence: {likelihood_name[safe.violence]}\")\n","    # print(f\"racy: {likelihood_name[safe.racy]}\")\n","    score = likelihood_name[safe.adult]+likelihood_name[safe.medical]+likelihood_name[safe.spoof]+likelihood_name[safe.violence]+likelihood_name[safe.racy]\n","\n","\n","    if response.error.message:\n","        raise Exception(\n","            \"{}\\nFor more info on error messages, check: \"\n","            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n","        )\n","    return score\n","for idx, col in enumerate(df['썸네일 주소']):\n","    df.loc[idx, '유해성 수치'] = detect_safe_search(col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dXzuqXEb362_"},"outputs":[],"source":["df"]},{"cell_type":"markdown","metadata":{"id":"bZWc7clHV2gr"},"source":["## RGB 값 컬럼 추가 코드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z0UjxkyqKtBS"},"outputs":[],"source":["def detect_properties(image_url):\n","    \"\"\"Detects image properties in the file.\"\"\"\n","    from google.cloud import vision\n","    client = vision_v1.ImageAnnotatorClient()\n","    image = vision_v1.Image()\n","    image.source.image_uri = image_url\n","\n","\n","    response = client.image_properties(image=image)\n","    props = response.image_properties_annotation\n","    # print(\"Properties:\")\n","    fraction = []\n","    max = 0\n","    cnt = 0\n","    for color in props.dominant_colors.colors:\n","        fraction.append([color.pixel_fraction,color.color.red,color.color.green,color.color.blue])\n","    for idx,i in enumerate(fraction):\n","        if max < fraction[idx][0]:\n","            max = fraction[idx][0]\n","            cnt = idx\n","    # print(fraction[cnt])\n","    # print(props)\n","    # print(fraction)\n","    # print(fraction[cnt])\n","\n","        # print(f\"\\tr: {color.color.red}\")\n","        # print(f\"\\tg: {color.color.green}\")\n","        # print(f\"\\tb: {color.color.blue}\")\n","        # print(f\"\\ta: {color.color.alpha}\")\n","\n","    if response.error.message:\n","        raise Exception(\n","            \"{}\\nFor more info on error messages, check: \"\n","            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n","        )\n","    return fraction[cnt]\n","for idx, col in enumerate(df['썸네일 주소']):\n","    df.loc[idx, 'R'] = detect_properties(col)[1]\n","    df.loc[idx, 'G'] = detect_properties(col)[2]\n","    df.loc[idx, 'B'] = detect_properties(col)[3]\n","\n","df"]},{"cell_type":"markdown","metadata":{"id":"uWTeiSzYtBNS"},"source":["## 썸네일 텍스트 상중하 위치"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9y0pXfC3nd0X"},"outputs":[],"source":["img_path = []\n","with io.open(path, 'rb') as image_file:\n","    content = image_file.read()\n","image = vision.Image(content=content)\n","response = client.text_detection(image=image)\n","texts = response.text_annotations\n","\n","def process_image_with_text(img_path, texts):\n","    img = cv2.imread(img_path)\n","    roi_img = img.copy()\n","    height = img.shape[0]\n","    height1 = height * (1 / 3)\n","    height2 = height * (2 / 3)\n","    cnt = {\n","        'up': 0, 'middle': 0, 'down': 0,'none':0\n","    }\n","\n","    if not texts:  # 텍스트가 없는 경우\n","        cnt['none']+=1\n","    else:\n","        for text in texts[1:-1]:\n","            print('\\n\"{}\"'.format(text.description))\n","\n","            vertices = (['({},{})'.format(vertex.x, vertex.y)\n","                         for vertex in text.bounding_poly.vertices])\n","\n","            ocr_text = text.description\n","            y1 = text.bounding_poly.vertices[0].y\n","            y2 = text.bounding_poly.vertices[2].y\n","\n","            m_y = (abs(y2 + y1)) // 2\n","            print(m_y)\n","            if 0 <= m_y < height1:\n","                cnt['up'] += len(ocr_text)\n","            elif height1 <= m_y < height2:\n","                cnt['middle'] += len(ocr_text)\n","            elif height2 <= m_y:\n","                cnt['down'] += len(ocr_text)\n","        if response.error.message:\n","            raise Exception(\n","                '{}\\nFor more info on error messages, check: '\n","                'https://cloud.google.com/apis/design/errors'.format(\n","                    response.error.message))\n","    return(max(cnt))\n","\n","for idx, col in 이미지파일 경로:\n","    df.loc[idx, '텍스트 위치'] = process_image_with_text(col,texts)"]},{"cell_type":"markdown","metadata":{"id":"b76hbNV_xQL_"},"source":["## 사람 수 카운트 (얼굴 기준)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zuVxei-LxPdD"},"outputs":[],"source":["def detect_faces_uri(image_path):\n","\n","\n","    client = vision.ImageAnnotatorClient()\n","\n","    # 이미지 파일을 읽어옵니다.\n","    with open(image_path, 'rb') as image_file:\n","        content = image_file.read()\n","\n","    # 이미지 데이터를 Vision API로 전송합니다.\n","    image = vision.Image(content=content)\n","\n","    response = client.face_detection(image=image)\n","    faces = response.face_annotations\n","\n","    if response.error.message:\n","        raise Exception(\n","            \"{}\\nFor more info on error messages, check: \"\n","            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n","        )\n","    return len(faces)\n","for idx, col in 이미지파일 경로:\n","    df.loc[idx, '썸네일 사람수'] = detect_faces_uri(image_path)\n","df[(df['썸네일 사람수']<3) & (df['썸네일 사람수']>=1)] = 1\n","df[df['썸네일 사람수']>=3] = 2"]}],"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
